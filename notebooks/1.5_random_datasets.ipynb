{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# 1.5 Promiscuity-Controlled Random Gene Sampling\n\nGenerate random gene samples controlling for gene promiscuity (number of GO term annotations).\n\n## Inputs\n- `output/intermediate/hetio_bppg_dataset2_filtered.csv` (2016 filtered)\n- `output/intermediate/hetio_bppg_dataset2_2024_filtered.csv` (2024 filtered)\n- `input/BPpG.csv` (all 2016 BP-Gene associations)\n- Remote: 2024 GO annotations from gene-ontology repository\n- `input/hetionet_neo4j_go_ids_nr.csv`\n- `input/hetionet_neo4j_genes_ids_nr.csv`\n- `input/Gene.tsv`\n\n## Outputs\n- `output/random_samples/dataset2_2016/random_001.csv` through `random_005.csv`\n- `output/random_samples/dataset2_2024/random_001.csv` through `random_005.csv`\n\n## Description\nThis notebook generates 5 random gene samples per year that control for gene promiscuity.\nFor each real gene in a GO term, we sample a random gene from OTHER GO terms\nthat has a similar number of GO annotations (promiscuity).\n\nThis approach ensures:\n1. Same number of genes per GO term\n2. Genes are sampled from other GO terms (not unannotated)\n3. Promiscuity distribution is matched (within tolerance)\n4. Multiple samples for robust statistical testing (matching permutation approach)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport sys\nfrom pathlib import Path\n\n# Setup repo root for consistent paths\n# Works whether notebook is run from repo root or notebooks/ subdirectory\nif Path.cwd().name == \"notebooks\":\n    repo_root = Path(\"..\").resolve()\nelse:\n    repo_root = Path.cwd()\n\nsys.path.insert(0, str(repo_root))\nfrom src.random_sampling import (\n    generate_promiscuity_controlled_samples,\n    calculate_gene_promiscuity\n)\n\n(repo_root / 'output/random_samples/dataset2_2016').mkdir(\n    parents=True, exist_ok=True\n)\n(repo_root / 'output/random_samples/dataset2_2024').mkdir(\n    parents=True, exist_ok=True\n)\n\nprint(f'Repo root: {repo_root}')\nprint('Environment setup complete')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load filtered datasets and original GO annotations for promiscuity calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Load filtered datasets from notebook 1.3\nreal_2016 = pd.read_csv(\n    repo_root / 'output/intermediate/hetio_bppg_dataset2_filtered.csv'\n)\nreal_2024 = pd.read_csv(\n    repo_root / 'output/intermediate/hetio_bppg_dataset2_2024_filtered.csv'\n)\n\nprint('Filtered GO-Gene Associations Loaded')\nprint('=' * 80)\nprint(f'2016: {len(real_2016):,} GO-gene pairs')\nprint(f'      {real_2016[\"go_id\"].nunique()} unique GO terms')\nprint(f'      {real_2016[\"neo4j_target_id\"].nunique()} unique genes')\n\nprint(f'\\n2024: {len(real_2024):,} GO-gene pairs')\nprint(f'      {real_2024[\"go_id\"].nunique()} unique GO terms')\nprint(f'      {real_2024[\"neo4j_target_id\"].nunique()} unique genes')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# Load ALL BP-Gene associations for promiscuity calculation\n# We need the full dataset to accurately count how many terms each gene belongs to\n\n# For 2016: Load original Hetionet BP-Gene edges from BPpG.csv\nall_bpg_2016 = pd.read_csv(repo_root / 'input/BPpG.csv')\n\n# Extract GO ID, gene ID (target_id), and create Neo4j source ID mapping\nneo4j_go = pd.read_csv(repo_root / 'input/hetionet_neo4j_go_ids_nr.csv')\nneo4j_genes = pd.read_csv(repo_root / 'input/hetionet_neo4j_genes_ids_nr.csv')\n\n# BPpG.csv target_id is Hetionet's internal node index, need to map to Entrez ID then Neo4j API ID\n# Load Gene.tsv to map Hetionet index to Entrez Gene ID\ngene_mapping = pd.read_csv(repo_root / 'input/Gene.tsv', sep='\\t')\ngene_mapping['hetionet_internal_id'] = gene_mapping.index\n\n# Map BPpG target_id (Hetionet index) to Entrez Gene ID\nall_bpg_2016 = all_bpg_2016.merge(\n    gene_mapping[['hetionet_internal_id', 'identifier']],\n    left_on='target_id',\n    right_on='hetionet_internal_id',\n    how='inner'\n)\nall_bpg_2016 = all_bpg_2016.rename(columns={'identifier': 'entrez_gene_id'})\nall_bpg_2016['entrez_gene_id'] = all_bpg_2016['entrez_gene_id'].astype(int)\n\n# Map Entrez Gene ID to Neo4j API node ID\nall_bpg_2016 = all_bpg_2016.merge(\n    neo4j_genes[['entrez_gene_id', 'neo4j_target_id']],\n    on='entrez_gene_id',\n    how='inner'\n)\n\n# Map GO ID to Neo4j source ID\nall_bpg_2016 = all_bpg_2016.merge(\n    neo4j_go[['go_id', 'neo4j_source_id']],\n    left_on='source_id',\n    right_on='go_id',\n    how='inner'\n)\n\n# Keep only needed columns\nall_bpg_2016 = all_bpg_2016[['go_id', 'neo4j_source_id', 'neo4j_target_id']]\n\nprint(f'\\nAll 2016 BP-Gene associations: {len(all_bpg_2016):,}')\nprint(f'  {all_bpg_2016[\"go_id\"].nunique()} GO terms')\nprint(f'  {all_bpg_2016[\"neo4j_target_id\"].nunique()} genes')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# For 2024: Load updated GO annotations from remote source\nupd_go_2024_raw = pd.read_csv(\n    'https://raw.githubusercontent.com/NegarJanani/gene-ontology/refs/heads/gh-pages/annotations/taxid_9606/GO_annotations-9606-inferred-allev.tsv',\n    sep='\\t'\n)\n\n# Expand gene IDs and symbols (same as notebook 1.1)\nexp_df = upd_go_2024_raw.assign(\n    gene_id=upd_go_2024_raw['gene_ids'].str.split('|'),\n    gene_symbol=upd_go_2024_raw['gene_symbols'].str.split('|')\n)\nupd_go_2024_df = exp_df.explode(['gene_id', 'gene_symbol'])\n\n# Clean data\nupd_go_2024_df['gene_id'] = upd_go_2024_df['gene_id'].str.strip()\nupd_go_2024_df['gene_symbol'] = upd_go_2024_df['gene_symbol'].str.strip()\nupd_go_2024_df = upd_go_2024_df[upd_go_2024_df['gene_id'] != '...']\nupd_go_2024_df['gene_id'] = upd_go_2024_df['gene_id'].astype(int)\n\n# Filter to Biological Process\nupd_go_bp_2024_df = upd_go_2024_df[\n    upd_go_2024_df['go_domain'] == 'biological_process'\n].copy()\nupd_go_bp_2024_df = upd_go_bp_2024_df[['go_id', 'go_name', 'gene_id', 'gene_symbol']]\nupd_go_bp_2024_df.rename(columns={'gene_id': 'entrez_gene_id'}, inplace=True)\n\n# Filter to Hetionet genes only\nhetio_genes_df = pd.read_csv(repo_root / 'input/Gene.tsv', sep='\\t')\nhetio_genes = hetio_genes_df['identifier'].unique()\nupd_go_bp_2024_df = upd_go_bp_2024_df[\n    upd_go_bp_2024_df['entrez_gene_id'].isin(hetio_genes)\n]\n\n# Map to Neo4j IDs\nupd_go_bp_2024_df = upd_go_bp_2024_df.merge(\n    neo4j_genes[['entrez_gene_id', 'neo4j_target_id']],\n    on='entrez_gene_id',\n    how='inner'\n)\n\nupd_go_bp_2024_df = upd_go_bp_2024_df.merge(\n    neo4j_go[['go_id', 'neo4j_source_id']],\n    on='go_id',\n    how='inner'\n)\n\nall_bpg_2024 = upd_go_bp_2024_df[['go_id', 'neo4j_source_id', 'neo4j_target_id']]\nall_bpg_2024 = all_bpg_2024.drop_duplicates()\n\nprint(f'\\nAll 2024 BP-Gene associations: {len(all_bpg_2024):,}')\nprint(f'  {all_bpg_2024[\"go_id\"].nunique()} GO terms')\nprint(f'  {all_bpg_2024[\"neo4j_target_id\"].nunique()} genes')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Calculate Gene Promiscuity\n",
    "\n",
    "Count how many GO terms each gene belongs to across the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate promiscuity for 2016\n",
    "promiscuity_2016 = calculate_gene_promiscuity(\n",
    "    all_bpg_2016,\n",
    "    go_id_col='go_id',\n",
    "    gene_id_col='neo4j_target_id'\n",
    ")\n",
    "\n",
    "print('2016 Gene Promiscuity Statistics')\n",
    "print('=' * 80)\n",
    "print(promiscuity_2016['promiscuity'].describe())\n",
    "\n",
    "print(f'\\nMost promiscuous genes (2016):')\n",
    "top_2016 = promiscuity_2016.nlargest(10, 'promiscuity')\n",
    "for _, row in top_2016.iterrows():\n",
    "    print(f\"  Gene {row['neo4j_target_id']}: \"\n",
    "          f\"{row['promiscuity']} GO terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate promiscuity for 2024\n",
    "promiscuity_2024 = calculate_gene_promiscuity(\n",
    "    all_bpg_2024,\n",
    "    go_id_col='go_id',\n",
    "    gene_id_col='neo4j_target_id'\n",
    ")\n",
    "\n",
    "print('2024 Gene Promiscuity Statistics')\n",
    "print('=' * 80)\n",
    "print(promiscuity_2024['promiscuity'].describe())\n",
    "\n",
    "print(f'\\nMost promiscuous genes (2024):')\n",
    "top_2024 = promiscuity_2024.nlargest(10, 'promiscuity')\n",
    "for _, row in top_2024.iterrows():\n",
    "    print(f\"  Gene {row['neo4j_target_id']}: \"\n",
    "          f\"{row['promiscuity']} GO terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": "## Generate Random Samples for 2016\n\nGenerate 5 independent random samples with different random seeds."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "print('Generating 5 promiscuity-controlled random samples for 2016...')\nprint('=' * 80)\n\nrandom_samples_2016 = []\n\nfor i in range(1, 6):\n    print(f'\\nGenerating random sample {i}/5...')\n    \n    random_sample = generate_promiscuity_controlled_samples(\n        go_gene_df=real_2016,\n        all_go_annotations=all_bpg_2016,\n        go_id_col='go_id',\n        gene_id_col='neo4j_target_id',\n        source_id_col='neo4j_source_id',\n        promiscuity_tolerance=2,\n        random_state=42 + i\n    )\n    \n    random_samples_2016.append(random_sample)\n    \n    print(f'  Generated {len(random_sample):,} pairs, '\n          f'{random_sample[\"go_id\"].nunique()} GO terms, '\n          f'{random_sample[\"neo4j_pseudo_target_id\"].nunique()} unique genes')\n    print(f'  Real promiscuity: mean={random_sample[\"real_promiscuity\"].mean():.2f}')\n    print(f'  Random promiscuity: mean={random_sample[\"sampled_promiscuity\"].mean():.2f}')\n\nprint('\\n2016 random samples complete')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": "## Generate Random Samples for 2024\n\nGenerate 5 independent random samples for 2024 data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "print('Generating 5 promiscuity-controlled random samples for 2024...')\nprint('=' * 80)\n\nrandom_samples_2024 = []\n\nfor i in range(1, 6):\n    print(f'\\nGenerating random sample {i}/5...')\n    \n    random_sample = generate_promiscuity_controlled_samples(\n        go_gene_df=real_2024,\n        all_go_annotations=all_bpg_2024,\n        go_id_col='go_id',\n        gene_id_col='neo4j_target_id',\n        source_id_col='neo4j_source_id',\n        promiscuity_tolerance=2,\n        random_state=42 + i\n    )\n    \n    random_samples_2024.append(random_sample)\n    \n    print(f'  Generated {len(random_sample):,} pairs, '\n          f'{random_sample[\"go_id\"].nunique()} GO terms, '\n          f'{random_sample[\"neo4j_pseudo_target_id\"].nunique()} unique genes')\n    print(f'  Real promiscuity: mean={random_sample[\"real_promiscuity\"].mean():.2f}')\n    print(f'  Random promiscuity: mean={random_sample[\"sampled_promiscuity\"].mean():.2f}')\n\nprint('\\n2024 random samples complete')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Verify that random samples have expected properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "print('\\n' + '=' * 80)\nprint('VALIDATION: Sample Sizes')\nprint('=' * 80)\n\n# Validate all 2016 samples\nfor i, random_2016 in enumerate(random_samples_2016, start=1):\n    real_2016_sizes = real_2016.groupby('go_id').size()\n    random_2016_sizes = random_2016.groupby('go_id').size()\n    \n    if (real_2016_sizes == random_2016_sizes).all():\n        print(f'2016 Sample {i}: Sample sizes match (PASS)')\n    else:\n        print(f'2016 Sample {i}: Sample sizes differ (FAIL)')\n\n# Validate all 2024 samples\nfor i, random_2024 in enumerate(random_samples_2024, start=1):\n    real_2024_sizes = real_2024.groupby('go_id').size()\n    random_2024_sizes = random_2024.groupby('go_id').size()\n    \n    if (real_2024_sizes == random_2024_sizes).all():\n        print(f'2024 Sample {i}: Sample sizes match (PASS)')\n    else:\n        print(f'2024 Sample {i}: Sample sizes differ (FAIL)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "print('\\n' + '=' * 80)\nprint('VALIDATION: No Overlap with Real Genes per GO Term')\nprint('=' * 80)\n\n# Check all 2016 samples\nfor i, random_2016 in enumerate(random_samples_2016, start=1):\n    overlap_count = 0\n    for go_id in real_2016['go_id'].unique():\n        real_genes = set(\n            real_2016[real_2016['go_id'] == go_id]['neo4j_target_id']\n        )\n        random_genes = set(\n            random_2016[random_2016['go_id'] == go_id]['neo4j_pseudo_target_id']\n        )\n        overlap = len(real_genes & random_genes)\n        overlap_count += overlap\n    \n    if overlap_count == 0:\n        print(f'2016 Sample {i}: No overlap (PASS)')\n    else:\n        print(f'2016 Sample {i}: Found {overlap_count} overlaps (FAIL)')\n\n# Check all 2024 samples\nfor i, random_2024 in enumerate(random_samples_2024, start=1):\n    overlap_count = 0\n    for go_id in real_2024['go_id'].unique():\n        real_genes = set(\n            real_2024[real_2024['go_id'] == go_id]['neo4j_target_id']\n        )\n        random_genes = set(\n            random_2024[random_2024['go_id'] == go_id]['neo4j_pseudo_target_id']\n        )\n        overlap = len(real_genes & random_genes)\n        overlap_count += overlap\n    \n    if overlap_count == 0:\n        print(f'2024 Sample {i}: No overlap (PASS)')\n    else:\n        print(f'2024 Sample {i}: Found {overlap_count} overlaps (FAIL)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "print('\\n' + '=' * 80)\nprint('VALIDATION: All Random Genes Are Annotated')\nprint('=' * 80)\n\nall_annotated_2016 = set(all_bpg_2016['neo4j_target_id'])\nall_annotated_2024 = set(all_bpg_2024['neo4j_target_id'])\n\n# Check all 2016 samples\nfor i, random_2016 in enumerate(random_samples_2016, start=1):\n    random_genes = set(random_2016['neo4j_pseudo_target_id'])\n    unannotated = random_genes - all_annotated_2016\n    \n    if len(unannotated) == 0:\n        print(f'2016 Sample {i}: All genes annotated (PASS)')\n    else:\n        print(f'2016 Sample {i}: Found {len(unannotated)} unannotated (FAIL)')\n\n# Check all 2024 samples\nfor i, random_2024 in enumerate(random_samples_2024, start=1):\n    random_genes = set(random_2024['neo4j_pseudo_target_id'])\n    unannotated = random_genes - all_annotated_2024\n    \n    if len(unannotated) == 0:\n        print(f'2024 Sample {i}: All genes annotated (PASS)')\n    else:\n        print(f'2024 Sample {i}: Found {len(unannotated)} unannotated (FAIL)')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": "print('\\nSaving random samples...')\n\nrandom_dir_2016 = repo_root / 'output/random_samples/dataset2_2016'\nrandom_dir_2024 = repo_root / 'output/random_samples/dataset2_2024'\n\n# Save 2016 samples\nfor i, random_sample in enumerate(random_samples_2016, start=1):\n    output_path = random_dir_2016 / f'random_{i:03d}.csv'\n    random_sample.to_csv(output_path, index=False)\n    print(f'  Saved random_{i:03d}.csv: {len(random_sample):,} pairs')\n\n# Save 2024 samples\nfor i, random_sample in enumerate(random_samples_2024, start=1):\n    output_path = random_dir_2024 / f'random_{i:03d}.csv'\n    random_sample.to_csv(output_path, index=False)\n    print(f'  Saved random_{i:03d}.csv: {len(random_sample):,} pairs')\n\nprint('\\n' + '=' * 80)\nprint('NOTEBOOK 1.5 COMPLETE')\nprint('=' * 80)\n\nprint('\\nGenerated Control Datasets:')\nprint('  Permuted datasets (1.4): 5 permutations per year (shuffle GO labels)')\nprint('  Random datasets (1.5): 5 random samples per year (promiscuity-controlled)')\nprint('  Total: 20 control datasets + 2 real datasets = 22 datasets')\n\nprint('\\nOutput Files:')\nprint('  output/permutations/dataset2_2016/perm_001.csv through perm_005.csv')\nprint('  output/permutations/dataset2_2024/perm_001.csv through perm_005.csv')\nprint('  output/random_samples/dataset2_2016/random_001.csv through random_005.csv')\nprint('  output/random_samples/dataset2_2024/random_001.csv through random_005.csv')\n\nprint('\\nNext Steps:')\nprint('  Run notebook 2 to compute DWPC for all 22 datasets')\nprint('  Expected runtime: Variable (depends on API performance)')\nprint('  Each dataset takes 30-60 minutes')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}