{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Jaccard Similarity Analysis and Filtering\n",
    "\n",
    "Calculate Jaccard similarity between GO terms and filter overlapping terms.\n",
    "\n",
    "## Inputs\n",
    "- `output/intermediate/hetio_bppg_2016_stable.csv` (2016 stable genes)\n",
    "- `output/intermediate/upd_go_bp_2024_added.csv` (2024 added genes)\n",
    "- `output/intermediate/dataset1_all_growth.csv`\n",
    "- `output/intermediate/dataset2_parents.csv`\n",
    "- `input/hetionet_neo4j_go_ids_nr.csv`\n",
    "- `input/hetionet_neo4j_genes_ids_nr.csv`\n",
    "\n",
    "## Outputs\n",
    "- `output/intermediate/dataset1_filtered.csv`\n",
    "- `output/intermediate/dataset2_filtered.csv`\n",
    "- `output/intermediate/hetio_bppg_dataset1_filtered.csv` (2016 stable, Jaccard filtered)\n",
    "- `output/intermediate/hetio_bppg_dataset2_filtered.csv` (2016 stable, Jaccard filtered)\n",
    "- `output/intermediate/hetio_bppg_dataset1_2024_filtered.csv` (2024 added, Jaccard filtered)\n",
    "- `output/intermediate/hetio_bppg_dataset2_2024_filtered.csv` (2024 added, Jaccard filtered)\n",
    "- `output/jaccard_similarity/` (cached matrices)\n",
    "\n",
    "## Description\n",
    "This notebook calculates Jaccard similarity between GO terms based on\n",
    "gene overlap. Terms with Jaccard > 0.1 are clustered, and representatives\n",
    "are selected based on greatest percent change in gene count.\n",
    "\n",
    "**Gene Classification:**\n",
    "- 2016 datasets contain only stable genes (present in both 2016 and 2024)\n",
    "- 2024 datasets contain only added genes (only in 2024, not in 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sys\nimport os\nfrom pathlib import Path\n\n# Setup repo root for consistent paths\n# Works whether notebook is run from repo root or notebooks/ subdirectory\nif Path.cwd().name == \"notebooks\":\n    repo_root = Path(\"..\").resolve()\nelse:\n    repo_root = Path.cwd()\n\nsys.path.insert(0, str(repo_root))\nfrom src.similarity import load_or_calculate_jaccard\nfrom src.filtering import filter_overlapping_go_terms\n\n# Create output directories\n(repo_root / 'output/jaccard_similarity').mkdir(parents=True, exist_ok=True)\n(repo_root / 'output/intermediate').mkdir(parents=True, exist_ok=True)\n\nprint(f\"Repo root: {repo_root}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load data from previous notebooks\nhetio_BPpG_2016_stable = pd.read_csv(\n    repo_root / 'output/intermediate/hetio_bppg_2016_stable.csv'\n)\nupd_go_bp_2024_added = pd.read_csv(\n    repo_root / 'output/intermediate/upd_go_bp_2024_added.csv'\n)\ndataset1_all_growth = pd.read_csv(\n    repo_root / 'output/intermediate/dataset1_all_growth.csv'\n)\ndataset2_parents = pd.read_csv(\n    repo_root / 'output/intermediate/dataset2_parents.csv'\n)\n\nprint('Loaded classified gene datasets:')\nprint(f'  hetio_BPpG_2016_stable: {len(hetio_BPpG_2016_stable)} rows (stable genes)')\nprint(f'  upd_go_bp_2024_added: {len(upd_go_bp_2024_added)} rows (added genes)')\nprint(f'  dataset1_all_growth: {len(dataset1_all_growth)} GO terms')\nprint(f'  dataset2_parents: {len(dataset2_parents)} GO terms')"
  },
  {
   "cell_type": "markdown",
   "id": "pnm6tkjvixb",
   "metadata": {},
   "source": [
    "### Map to Neo4j Node IDs\n",
    "\n",
    "The Docker API requires Neo4j internal node IDs rather than biological identifiers (GO IDs, Entrez Gene IDs). This section loads the complete mapping files and filters them to only the IDs present in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hkn7inyzm1d",
   "metadata": {},
   "outputs": [],
   "source": "hetionet_neo4j_go_ids_complete = pd.read_csv(repo_root / 'input/hetionet_neo4j_go_ids_nr.csv')\nhetionet_neo4j_genes_complete = pd.read_csv(repo_root / 'input/hetionet_neo4j_genes_ids_nr.csv')\n\nprint(\"Complete Neo4j ID Mappings\")\nprint(\"=\" * 60)\nprint(f\"Total GO term mappings: {len(hetionet_neo4j_go_ids_complete)}\")\nprint(f\"Total gene mappings: {len(hetionet_neo4j_genes_complete)}\")\n\ngo_terms_dataset1 = set(dataset1_all_growth['go_id'])\ngo_terms_dataset2 = set(dataset2_parents['go_id'])\n\ngenes_2016_stable_dataset1 = set(hetio_BPpG_2016_stable[\n    hetio_BPpG_2016_stable['go_id'].isin(go_terms_dataset1)\n]['entrez_gene_id'])\n\ngenes_2016_stable_dataset2 = set(hetio_BPpG_2016_stable[\n    hetio_BPpG_2016_stable['go_id'].isin(go_terms_dataset2)\n]['entrez_gene_id'])\n\ngenes_2024_added_dataset1 = set(upd_go_bp_2024_added[\n    upd_go_bp_2024_added['go_id'].isin(go_terms_dataset1)\n]['entrez_gene_id'])\n\ngenes_2024_added_dataset2 = set(upd_go_bp_2024_added[\n    upd_go_bp_2024_added['go_id'].isin(go_terms_dataset2)\n]['entrez_gene_id'])\n\nprint(f\"\\nDataset 1 (All Growth Terms):\")\nprint(f\"  GO terms: {len(go_terms_dataset1)}\")\nprint(f\"  Genes (2016 stable): {len(genes_2016_stable_dataset1)}\")\nprint(f\"  Genes (2024 added): {len(genes_2024_added_dataset1)}\")\nprint(f\"  Total unique genes: {len(genes_2016_stable_dataset1 | genes_2024_added_dataset1)}\")\n\nprint(f\"\\nDataset 2 (Parent Terms):\")\nprint(f\"  GO terms: {len(go_terms_dataset2)}\")\nprint(f\"  Genes (2016 stable): {len(genes_2016_stable_dataset2)}\")\nprint(f\"  Genes (2024 added): {len(genes_2024_added_dataset2)}\")\nprint(f\"  Total unique genes: {len(genes_2016_stable_dataset2 | genes_2024_added_dataset2)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mf0tpuqkq1o",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_go_mapping_dataset1 = hetionet_neo4j_go_ids_complete[\n",
    "    hetionet_neo4j_go_ids_complete['go_id'].isin(go_terms_dataset1)\n",
    "].copy()\n",
    "\n",
    "neo4j_gene_mapping_dataset1 = hetionet_neo4j_genes_complete[\n",
    "    hetionet_neo4j_genes_complete['entrez_gene_id'].isin(\n",
    "        genes_2016_stable_dataset1 | genes_2024_added_dataset1\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "neo4j_go_mapping_dataset2 = hetionet_neo4j_go_ids_complete[\n",
    "    hetionet_neo4j_go_ids_complete['go_id'].isin(go_terms_dataset2)\n",
    "].copy()\n",
    "\n",
    "neo4j_gene_mapping_dataset2 = hetionet_neo4j_genes_complete[\n",
    "    hetionet_neo4j_genes_complete['entrez_gene_id'].isin(\n",
    "        genes_2016_stable_dataset2 | genes_2024_added_dataset2\n",
    "    )\n",
    "].copy()\n",
    "\n",
    "print(\"Dataset 1 (All Growth Terms) - Neo4j Mappings\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"GO term mappings: {len(neo4j_go_mapping_dataset1)}\")\n",
    "print(f\"Gene mappings: {len(neo4j_gene_mapping_dataset1)}\")\n",
    "print(f\"\\nMissing mappings:\")\n",
    "print(f\"  GO terms without Neo4j ID: {len(go_terms_dataset1) - len(neo4j_go_mapping_dataset1)}\")\n",
    "print(f\"  Genes without Neo4j ID: {len(genes_2016_stable_dataset1 | genes_2024_added_dataset1) - len(neo4j_gene_mapping_dataset1)}\")\n",
    "\n",
    "print(f\"\\n\\nDataset 2 (Parent Terms) - Neo4j Mappings\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"GO term mappings: {len(neo4j_go_mapping_dataset2)}\")\n",
    "print(f\"Gene mappings: {len(neo4j_gene_mapping_dataset2)}\")\n",
    "print(f\"\\nMissing mappings:\")\n",
    "print(f\"  GO terms without Neo4j ID: {len(go_terms_dataset2) - len(neo4j_go_mapping_dataset2)}\")\n",
    "print(f\"  Genes without Neo4j ID: {len(genes_2016_stable_dataset2 | genes_2024_added_dataset2) - len(neo4j_gene_mapping_dataset2)}\")\n",
    "\n",
    "print(f\"\\n\\nSample GO Mappings (Dataset 1):\")\n",
    "display(neo4j_go_mapping_dataset1.head())\n",
    "\n",
    "print(f\"\\nSample Gene Mappings (Dataset 1):\")\n",
    "display(neo4j_gene_mapping_dataset1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create merged dataframes with Neo4j IDs for Dataset 1\n",
    "hetio_BPpG_dataset1 = hetio_BPpG_2016_stable[\n",
    "    hetio_BPpG_2016_stable['go_id'].isin(go_terms_dataset1)\n",
    "].copy()\n",
    "\n",
    "upd_go_bp_2024_dataset1 = upd_go_bp_2024_added[\n",
    "    upd_go_bp_2024_added['go_id'].isin(go_terms_dataset1)\n",
    "].copy()\n",
    "\n",
    "# Merge with Neo4j mappings for Dataset 1\n",
    "hetio_BPpG_dataset1 = hetio_BPpG_dataset1.merge(\n",
    "    neo4j_go_mapping_dataset1,\n",
    "    on='go_id',\n",
    "    how='inner'\n",
    ").merge(\n",
    "    neo4j_gene_mapping_dataset1,\n",
    "    on='entrez_gene_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "upd_go_bp_2024_dataset1 = upd_go_bp_2024_dataset1.merge(\n",
    "    neo4j_go_mapping_dataset1,\n",
    "    on='go_id',\n",
    "    how='inner'\n",
    ").merge(\n",
    "    neo4j_gene_mapping_dataset1,\n",
    "    on='entrez_gene_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(\"Dataset 1 (All Growth Terms)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"2016 BP-Gene pairs (stable): {len(hetio_BPpG_dataset1)}\")\n",
    "print(f\"2024 BP-Gene pairs (added): {len(upd_go_bp_2024_dataset1)}\")\n",
    "print(f\"2016 unique GO terms: {hetio_BPpG_dataset1['go_id'].nunique()}\")\n",
    "print(f\"2024 unique GO terms: {upd_go_bp_2024_dataset1['go_id'].nunique()}\")\n",
    "\n",
    "# Create merged dataframes with Neo4j IDs for Dataset 2\n",
    "hetio_BPpG_dataset2 = hetio_BPpG_2016_stable[\n",
    "    hetio_BPpG_2016_stable['go_id'].isin(go_terms_dataset2)\n",
    "].copy()\n",
    "\n",
    "upd_go_bp_2024_dataset2 = upd_go_bp_2024_added[\n",
    "    upd_go_bp_2024_added['go_id'].isin(go_terms_dataset2)\n",
    "].copy()\n",
    "\n",
    "hetio_BPpG_dataset2 = hetio_BPpG_dataset2.merge(\n",
    "    neo4j_go_mapping_dataset2,\n",
    "    on='go_id',\n",
    "    how='inner'\n",
    ").merge(\n",
    "    neo4j_gene_mapping_dataset2,\n",
    "    on='entrez_gene_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "upd_go_bp_2024_dataset2 = upd_go_bp_2024_dataset2.merge(\n",
    "    neo4j_go_mapping_dataset2,\n",
    "    on='go_id',\n",
    "    how='inner'\n",
    ").merge(\n",
    "    neo4j_gene_mapping_dataset2,\n",
    "    on='entrez_gene_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(\"\\nDataset 2 (Parent Terms)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"2016 BP-Gene pairs (stable): {len(hetio_BPpG_dataset2)}\")\n",
    "print(f\"2024 BP-Gene pairs (added): {len(upd_go_bp_2024_dataset2)}\")\n",
    "print(f\"2016 unique GO terms: {hetio_BPpG_dataset2['go_id'].nunique()}\")\n",
    "print(f\"2024 unique GO terms: {upd_go_bp_2024_dataset2['go_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b8b23",
   "metadata": {},
   "source": [
    "### Create GO-Gene pair identifiers for both datasets\n",
    "\n",
    "Create unique identifiers combining GO term and gene for tracking pairs across 2016 and 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1: Create go_id_gene identifier\n",
    "hetio_BPpG_dataset1['go_id_gene'] = (\n",
    "    hetio_BPpG_dataset1['go_id'] + '|' + \n",
    "    hetio_BPpG_dataset1['neo4j_target_id'].astype(str)\n",
    ")\n",
    "\n",
    "upd_go_bp_2024_dataset1['go_id_gene'] = (\n",
    "    upd_go_bp_2024_dataset1['go_id'] + '|' + \n",
    "    upd_go_bp_2024_dataset1['neo4j_target_id'].astype(str)\n",
    ")\n",
    "\n",
    "print(\"Dataset 1 (All Growth Terms)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"2016 pairs (stable genes): {len(hetio_BPpG_dataset1)}\")\n",
    "print(f\"2024 pairs (added genes): {len(upd_go_bp_2024_dataset1)}\")\n",
    "print(f\"\\nNote: These gene sets are disjoint by design\")\n",
    "print(f\"  - 2016 contains only genes present in both 2016 and 2024\")\n",
    "print(f\"  - 2024 contains only genes added in 2024 (not in 2016)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480bdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 2: Create go_id_gene identifier\n",
    "hetio_BPpG_dataset2['go_id_gene'] = (\n",
    "    hetio_BPpG_dataset2['go_id'] + '|' + \n",
    "    hetio_BPpG_dataset2['neo4j_target_id'].astype(str)\n",
    ")\n",
    "\n",
    "upd_go_bp_2024_dataset2['go_id_gene'] = (\n",
    "    upd_go_bp_2024_dataset2['go_id'] + '|' + \n",
    "    upd_go_bp_2024_dataset2['neo4j_target_id'].astype(str)\n",
    ")\n",
    "\n",
    "print(\"Dataset 2 (Parent Terms)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"2016 pairs (stable genes): {len(hetio_BPpG_dataset2)}\")\n",
    "print(f\"2024 pairs (added genes): {len(upd_go_bp_2024_dataset2)}\")\n",
    "print(f\"\\nNote: These gene sets are disjoint by design\")\n",
    "print(f\"  - 2016 contains only genes present in both 2016 and 2024\")\n",
    "print(f\"  - 2024 contains only genes added in 2024 (not in 2016)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace418aa",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport matplotlib.pyplot as plt\n\n# Ensure output directory exists\noutput_dir = repo_root / \"output/images\"\noutput_dir.mkdir(parents=True, exist_ok=True)\n\n# Sort both datasets\ndataset1_sorted = dataset1_all_growth.sort_values(by=\"no_of_genes_in_hetio_GO_2016\", ascending=True).reset_index(drop=True)\ndataset2_sorted = dataset2_parents.sort_values(by=\"no_of_genes_in_hetio_GO_2016\", ascending=True).reset_index(drop=True)\n\n# Create figure with two subplots side by side\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=150)\n\n# Dataset 1: All Growth Terms\nax1 = axes[0]\nax1.plot(range(len(dataset1_sorted)), dataset1_sorted[\"no_of_genes_in_hetio_GO_2016\"], \n         marker=\"o\", linewidth=0.5, markersize=1, label=\"2016\", color=\"steelblue\")\nax1.plot(range(len(dataset1_sorted)), dataset1_sorted[\"no_of_genes_in_GO_2024\"], \n         marker=\"s\", linewidth=0.5, markersize=1, label=\"2024\", color=\"darkorange\")\nax1.set_xlabel(f\"GO Terms (n = {len(dataset1_sorted)})\", fontsize=11)\nax1.set_ylabel(\"Number of Genes\", fontsize=11)\nax1.set_title(\"Dataset 1: All Growth Terms\", fontsize=12)\nax1.legend(title=\"Year\", fontsize=10, title_fontsize=10)\nax1.grid(False)\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Dataset 2: Parent Terms\nax2 = axes[1]\nax2.plot(range(len(dataset2_sorted)), dataset2_sorted[\"no_of_genes_in_hetio_GO_2016\"], \n         marker=\"o\", linewidth=0.5, markersize=1, label=\"2016\", color=\"steelblue\")\nax2.plot(range(len(dataset2_sorted)), dataset2_sorted[\"no_of_genes_in_GO_2024\"], \n         marker=\"s\", linewidth=0.5, markersize=1, label=\"2024\", color=\"darkorange\")\nax2.set_xlabel(f\"GO Terms (n = {len(dataset2_sorted)})\", fontsize=11)\nax2.set_ylabel(\"Number of Genes\", fontsize=11)\nax2.set_title(\"Dataset 2: Parent Terms\", fontsize=12)\nax2.legend(title=\"Year\", fontsize=10, title_fontsize=10)\nax2.grid(False)\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\nplt.tight_layout()\n\n# Save figure\nplt.savefig(output_dir / \"genes_per_go_2016_vs_2024_both_datasets.pdf\", format=\"pdf\", dpi=300, bbox_inches='tight')\nplt.savefig(output_dir / \"genes_per_go_2016_vs_2024_both_datasets.jpeg\", format=\"jpeg\", dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"Figure saved to {output_dir}/genes_per_go_2016_vs_2024_both_datasets.pdf\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y402mtnpm8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_jaccard_similarity_optimized(go_term_genes_dict):\n",
    "    \"\"\"\n",
    "    Calculate pairwise Jaccard similarity between GO terms using scipy.\n",
    "    \n",
    "    This vectorized implementation is 10-50x faster than nested loops.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    go_term_genes_dict : dict\n",
    "        Dictionary mapping GO term IDs to sets of gene IDs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Symmetric matrix of Jaccard similarity scores between GO terms\n",
    "    \"\"\"\n",
    "    go_terms = list(go_term_genes_dict.keys())\n",
    "    n_terms = len(go_terms)\n",
    "    \n",
    "    print(f\"Creating binary feature matrix for {n_terms} GO terms...\")\n",
    "    \n",
    "    # Get all unique genes across all GO terms\n",
    "    all_genes = sorted(set().union(*go_term_genes_dict.values()))\n",
    "    n_genes = len(all_genes)\n",
    "    gene_to_idx = {gene: idx for idx, gene in enumerate(all_genes)}\n",
    "    \n",
    "    print(f\"Total unique genes: {n_genes}\")\n",
    "    \n",
    "    # Create binary feature matrix: rows=GO terms, cols=genes\n",
    "    # Use sparse representation if memory is a concern\n",
    "    feature_matrix = np.zeros((n_terms, n_genes), dtype=np.bool_)\n",
    "    \n",
    "    print(\"Populating feature matrix...\")\n",
    "    for i, term in enumerate(tqdm(go_terms, desc=\"Processing GO terms\")):\n",
    "        gene_indices = [gene_to_idx[gene] for gene in go_term_genes_dict[term]]\n",
    "        feature_matrix[i, gene_indices] = True\n",
    "    \n",
    "    print(\"Calculating pairwise Jaccard distances...\")\n",
    "    # Use scipy pdist which is often faster than sklearn for jaccard\n",
    "    condensed_distances = pdist(feature_matrix, metric='jaccard')\n",
    "    \n",
    "    print(\"Converting to square matrix...\")\n",
    "    distance_matrix = squareform(condensed_distances)\n",
    "    \n",
    "    # Convert distances to similarities\n",
    "    similarities = 1 - distance_matrix\n",
    "    \n",
    "    return pd.DataFrame(similarities, index=go_terms, columns=go_terms)\n",
    "\n",
    "def load_or_calculate_jaccard(go_term_genes_dict, cache_file):\n",
    "    \"\"\"\n",
    "    Load Jaccard similarity matrix from cache or calculate if not cached.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    go_term_genes_dict : dict\n",
    "        Dictionary mapping GO term IDs to sets of gene IDs\n",
    "    cache_file : str\n",
    "        Path to cache file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Jaccard similarity matrix\n",
    "    \"\"\"\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"Loading cached Jaccard matrix from {cache_file}\")\n",
    "        return pd.read_csv(cache_file, index_col=0)\n",
    "    else:\n",
    "        print(f\"Cache not found. Computing Jaccard similarity matrix...\")\n",
    "        similarity_matrix = calculate_jaccard_similarity_optimized(go_term_genes_dict)\n",
    "        \n",
    "        # Cache the result\n",
    "        os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n",
    "        print(f\"Saving to cache: {cache_file}\")\n",
    "        similarity_matrix.to_csv(cache_file)\n",
    "        print(f\"Cache saved successfully\")\n",
    "        \n",
    "        return similarity_matrix\n",
    "\n",
    "print(\"Optimized Jaccard similarity functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emnlycu4bn",
   "metadata": {},
   "outputs": [],
   "source": "# Prepare gene sets for each GO term in both datasets\n\n# Define cache directory first\njaccard_cache_dir = repo_root / \"output/jaccard_similarity\"\njaccard_cache_dir.mkdir(parents=True, exist_ok=True)\n\n# Dataset 1: 2016 data\ndataset1_2016_go_genes = {}\nfor go_id in dataset1_all_growth['go_id']:\n    genes = set(hetio_BPpG_dataset1[hetio_BPpG_dataset1['go_id'] == go_id]['entrez_gene_id'])\n    if len(genes) > 0:\n        dataset1_2016_go_genes[go_id] = genes\n\n# Dataset 1: 2024 data\ndataset1_2024_go_genes = {}\nfor go_id in dataset1_all_growth['go_id']:\n    genes = set(upd_go_bp_2024_dataset1[upd_go_bp_2024_dataset1['go_id'] == go_id]['entrez_gene_id'])\n    if len(genes) > 0:\n        dataset1_2024_go_genes[go_id] = genes\n\n# Dataset 2: 2016 data\ndataset2_2016_go_genes = {}\nfor go_id in dataset2_parents['go_id']:\n    genes = set(hetio_BPpG_dataset2[hetio_BPpG_dataset2['go_id'] == go_id]['entrez_gene_id'])\n    if len(genes) > 0:\n        dataset2_2016_go_genes[go_id] = genes\n\n# Dataset 2: 2024 data\ndataset2_2024_go_genes = {}\nfor go_id in dataset2_parents['go_id']:\n    genes = set(upd_go_bp_2024_dataset2[upd_go_bp_2024_dataset2['go_id'] == go_id]['entrez_gene_id'])\n    if len(genes) > 0:\n        dataset2_2024_go_genes[go_id] = genes\n\nprint(\"Gene sets prepared for Jaccard similarity calculation\")\nprint(\"=\" * 70)\nprint(\"Dataset 1 (All Growth Terms):\")\nprint(f\"  2016: {len(dataset1_2016_go_genes)} GO terms\")\nprint(f\"  2024: {len(dataset1_2024_go_genes)} GO terms\")\nprint(f\"\\nDataset 2 (Parent Terms):\")\nprint(f\"  2016: {len(dataset2_2016_go_genes)} GO terms\")\nprint(f\"  2024: {len(dataset2_2024_go_genes)} GO terms\")\nprint(\"=\" * 70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7yjjbqnq5s8",
   "metadata": {},
   "outputs": [],
   "source": "# Check if Jaccard similarity cache files exist\njaccard_cache_dir = repo_root / \"output/jaccard_similarity\"\ncache_files = {\n    'dataset1_2016': jaccard_cache_dir / \"jaccard_similarity_dataset1_2016.csv\",\n    'dataset1_2024': jaccard_cache_dir / \"jaccard_similarity_dataset1_2024.csv\",\n    'dataset2_2016': jaccard_cache_dir / \"jaccard_similarity_dataset2_2016.csv\",\n    'dataset2_2024': jaccard_cache_dir / \"jaccard_similarity_dataset2_2024.csv\"\n}\n\nprint(\"Checking for cached Jaccard similarity matrices...\")\nprint(\"=\" * 70)\nall_cached = True\nfor name, path in cache_files.items():\n    if path.exists():\n        size_kb = path.stat().st_size / 1024\n        print(f\"FOUND: {name:20s} ({size_kb:.1f} KB)\")\n    else:\n        print(f\"NOT FOUND: {name:20s} - will need to compute\")\n        all_cached = False\n\nif all_cached:\n    print(\"\\nAll cache files exist. Loading should be instant.\")\nelse:\n    print(\"\\nSome cache files missing. First computation may take 30-60 seconds.\")\n    print(\"Subsequent runs will be instant once cached.\")\n\nprint(f\"\\nTo force recalculation, delete the cache directory:\")\nprint(f\"  rm -rf {jaccard_cache_dir}\")\nprint(\"=\" * 70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uw1ktfwql1",
   "metadata": {},
   "outputs": [],
   "source": "# Load or calculate Jaccard similarity matrices with progress tracking\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"JACCARD SIMILARITY CALCULATION\")\nprint(\"=\" * 70)\n\n# Calculate for Dataset 1 - 2016\nprint(\"\\n[1/4] Dataset 1 - 2016...\")\njaccard_dataset1_2016 = load_or_calculate_jaccard(\n    dataset1_2016_go_genes, \n    str(jaccard_cache_dir / \"jaccard_similarity_dataset1_2016.csv\")\n)\n\n# Calculate for Dataset 1 - 2024\nprint(\"\\n[2/4] Dataset 1 - 2024...\")\njaccard_dataset1_2024 = load_or_calculate_jaccard(\n    dataset1_2024_go_genes,\n    str(jaccard_cache_dir / \"jaccard_similarity_dataset1_2024.csv\")\n)\n\n# Calculate for Dataset 2 - 2016\nprint(\"\\n[3/4] Dataset 2 - 2016...\")\njaccard_dataset2_2016 = load_or_calculate_jaccard(\n    dataset2_2016_go_genes,\n    str(jaccard_cache_dir / \"jaccard_similarity_dataset2_2016.csv\")\n)\n\n# Calculate for Dataset 2 - 2024\nprint(\"\\n[4/4] Dataset 2 - 2024...\")\njaccard_dataset2_2024 = load_or_calculate_jaccard(\n    dataset2_2024_go_genes,\n    str(jaccard_cache_dir / \"jaccard_similarity_dataset2_2024.csv\")\n)\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"ALL JACCARD MATRICES READY\")\nprint(\"=\" * 70)\n\n# Summary statistics\nprint(\"\\nDataset 1 - 2016 Jaccard Similarity:\")\nprint(f\"  Mean: {jaccard_dataset1_2016.values[np.triu_indices_from(jaccard_dataset1_2016.values, k=1)].mean():.4f}\")\nprint(f\"  Median: {np.median(jaccard_dataset1_2016.values[np.triu_indices_from(jaccard_dataset1_2016.values, k=1)]):.4f}\")\nprint(f\"  Max (off-diagonal): {jaccard_dataset1_2016.values[np.triu_indices_from(jaccard_dataset1_2016.values, k=1)].max():.4f}\")\n\nprint(\"\\nDataset 1 - 2024 Jaccard Similarity:\")\nprint(f\"  Mean: {jaccard_dataset1_2024.values[np.triu_indices_from(jaccard_dataset1_2024.values, k=1)].mean():.4f}\")\nprint(f\"  Median: {np.median(jaccard_dataset1_2024.values[np.triu_indices_from(jaccard_dataset1_2024.values, k=1)]):.4f}\")\nprint(f\"  Max (off-diagonal): {jaccard_dataset1_2024.values[np.triu_indices_from(jaccard_dataset1_2024.values, k=1)].max():.4f}\")\n\nprint(\"\\nDataset 2 - 2016 Jaccard Similarity:\")\nprint(f\"  Mean: {jaccard_dataset2_2016.values[np.triu_indices_from(jaccard_dataset2_2016.values, k=1)].mean():.4f}\")\nprint(f\"  Median: {np.median(jaccard_dataset2_2016.values[np.triu_indices_from(jaccard_dataset2_2016.values, k=1)]):.4f}\")\nprint(f\"  Max (off-diagonal): {jaccard_dataset2_2016.values[np.triu_indices_from(jaccard_dataset2_2016.values, k=1)].max():.4f}\")\n\nprint(\"\\nDataset 2 - 2024 Jaccard Similarity:\")\nprint(f\"  Mean: {jaccard_dataset2_2024.values[np.triu_indices_from(jaccard_dataset2_2024.values, k=1)].mean():.4f}\")\nprint(f\"  Median: {np.median(jaccard_dataset2_2024.values[np.triu_indices_from(jaccard_dataset2_2024.values, k=1)]):.4f}\")\nprint(f\"  Max (off-diagonal): {jaccard_dataset2_2024.values[np.triu_indices_from(jaccard_dataset2_2024.values, k=1)].max():.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "he0cfg47u2n",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# OPTIONAL: Skip heatmap generation if too slow (large matrices can take minutes)\n",
    "# Set to True to skip this cell\n",
    "SKIP_HEATMAPS = True\n",
    "\n",
    "if SKIP_HEATMAPS:\n",
    "    print(\"Heatmap generation skipped (set SKIP_HEATMAPS=False to generate)\")\n",
    "else:\n",
    "    print(\"Generating clustered heatmaps (this may take 1-2 minutes for large datasets)...\")\n",
    "    \n",
    "    # Create 2x2 heatmap figure with hierarchical clustering\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 14), dpi=150)\n",
    "    \n",
    "    # Create mask for diagonal\n",
    "    def create_diagonal_mask(size):\n",
    "        mask = np.zeros((size, size), dtype=bool)\n",
    "        np.fill_diagonal(mask, True)\n",
    "        return mask\n",
    "    \n",
    "    def plot_clustered_heatmap(similarity_matrix, ax, title):\n",
    "        \"\"\"\n",
    "        Plot heatmap with hierarchical clustering and no diagonal.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        similarity_matrix : pd.DataFrame\n",
    "            Jaccard similarity matrix\n",
    "        ax : matplotlib axes\n",
    "            Axes to plot on\n",
    "        title : str\n",
    "            Plot title\n",
    "        \"\"\"\n",
    "        print(f\"  Clustering {len(similarity_matrix)} GO terms for: {title}\")\n",
    "        \n",
    "        # Convert similarity to distance for clustering\n",
    "        distance_matrix = 1 - similarity_matrix.values\n",
    "        \n",
    "        # Perform hierarchical clustering\n",
    "        condensed_dist = squareform(distance_matrix, checks=False)\n",
    "        linkage_matrix = linkage(condensed_dist, method='average')\n",
    "        \n",
    "        # Get dendrogram order\n",
    "        dend = dendrogram(linkage_matrix, no_plot=True)\n",
    "        order = dend['leaves']\n",
    "        \n",
    "        # Reorder matrix by clustering\n",
    "        clustered_matrix = similarity_matrix.iloc[order, order]\n",
    "        \n",
    "        # Create mask for diagonal\n",
    "        mask = create_diagonal_mask(len(clustered_matrix))\n",
    "        \n",
    "        # Plot heatmap with adjusted scale for sparse data\n",
    "        sns.heatmap(clustered_matrix, cmap=\"YlOrRd\", vmin=0, vmax=0.8, \n",
    "                    mask=mask, square=True, cbar_kws={'label': 'Jaccard Similarity'}, \n",
    "                    ax=ax, xticklabels=False, yticklabels=False)\n",
    "        ax.set_title(title, fontsize=12)\n",
    "        ax.set_xlabel(\"GO Terms (clustered)\", fontsize=11)\n",
    "        ax.set_ylabel(\"GO Terms (clustered)\", fontsize=11)\n",
    "    \n",
    "    # Dataset 1 - 2016\n",
    "    plot_clustered_heatmap(\n",
    "        jaccard_dataset1_2016, \n",
    "        axes[0, 0],\n",
    "        f\"Dataset 1 (2016): All Growth Terms\\n(n = {len(dataset1_2016_go_genes)} GO terms)\"\n",
    "    )\n",
    "    \n",
    "    # Dataset 1 - 2024\n",
    "    plot_clustered_heatmap(\n",
    "        jaccard_dataset1_2024,\n",
    "        axes[0, 1],\n",
    "        f\"Dataset 1 (2024): All Growth Terms\\n(n = {len(dataset1_2024_go_genes)} GO terms)\"\n",
    "    )\n",
    "    \n",
    "    # Dataset 2 - 2016\n",
    "    plot_clustered_heatmap(\n",
    "        jaccard_dataset2_2016,\n",
    "        axes[1, 0],\n",
    "        f\"Dataset 2 (2016): Parent Terms\\n(n = {len(dataset2_2016_go_genes)} GO terms)\"\n",
    "    )\n",
    "    \n",
    "    # Dataset 2 - 2024\n",
    "    plot_clustered_heatmap(\n",
    "        jaccard_dataset2_2024,\n",
    "        axes[1, 1],\n",
    "        f\"Dataset 2 (2024): Parent Terms\\n(n = {len(dataset2_2024_go_genes)} GO terms)\"\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(os.path.join(output_dir, \"jaccard_similarity_heatmaps_clustered_both_datasets.pdf\"), \n",
    "                format=\"pdf\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(output_dir, \"jaccard_similarity_heatmaps_clustered_both_datasets.jpeg\"), \n",
    "                format=\"jpeg\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nCluster ed heatmaps saved to {output_dir}/jaccard_similarity_heatmaps_clustered_both_datasets.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3j4t58e5yxw",
   "metadata": {},
   "outputs": [],
   "source": "# Analyze distribution of Jaccard similarity values\n\n# Create histograms showing distribution of similarity scores\nfig, axes = plt.subplots(2, 2, figsize=(14, 10), dpi=150)\n\n# Get upper triangle indices (exclude diagonal)\ndef get_upper_triangle(matrix):\n    mask = np.triu_indices_from(matrix.values, k=1)\n    return matrix.values[mask]\n\n# Dataset 1 - 2016\nax1 = axes[0, 0]\nvalues_d1_2016 = get_upper_triangle(jaccard_dataset1_2016)\nax1.hist(values_d1_2016, bins=50, edgecolor='black', alpha=0.7)\nax1.axvline(x=values_d1_2016.mean(), color='red', linestyle='--', linewidth=2, \n            label=f'Mean = {values_d1_2016.mean():.3f}')\nax1.axvline(x=np.median(values_d1_2016), color='blue', linestyle='--', linewidth=2, \n            label=f'Median = {np.median(values_d1_2016):.3f}')\nax1.set_xlabel('Jaccard Similarity', fontsize=11)\nax1.set_ylabel('Frequency', fontsize=11)\nax1.set_title('Dataset 1 (2016): All Growth Terms', fontsize=12)\nax1.legend()\nax1.spines['top'].set_visible(False)\nax1.spines['right'].set_visible(False)\n\n# Dataset 1 - 2024\nax2 = axes[0, 1]\nvalues_d1_2024 = get_upper_triangle(jaccard_dataset1_2024)\nax2.hist(values_d1_2024, bins=50, edgecolor='black', alpha=0.7, color='orange')\nax2.axvline(x=values_d1_2024.mean(), color='red', linestyle='--', linewidth=2, \n            label=f'Mean = {values_d1_2024.mean():.3f}')\nax2.axvline(x=np.median(values_d1_2024), color='blue', linestyle='--', linewidth=2, \n            label=f'Median = {np.median(values_d1_2024):.3f}')\nax2.set_xlabel('Jaccard Similarity', fontsize=11)\nax2.set_ylabel('Frequency', fontsize=11)\nax2.set_title('Dataset 1 (2024): All Growth Terms', fontsize=12)\nax2.legend()\nax2.spines['top'].set_visible(False)\nax2.spines['right'].set_visible(False)\n\n# Dataset 2 - 2016\nax3 = axes[1, 0]\nvalues_d2_2016 = get_upper_triangle(jaccard_dataset2_2016)\nax3.hist(values_d2_2016, bins=50, edgecolor='black', alpha=0.7, color='green')\nax3.axvline(x=values_d2_2016.mean(), color='red', linestyle='--', linewidth=2, \n            label=f'Mean = {values_d2_2016.mean():.3f}')\nax3.axvline(x=np.median(values_d2_2016), color='blue', linestyle='--', linewidth=2, \n            label=f'Median = {np.median(values_d2_2016):.3f}')\nax3.set_xlabel('Jaccard Similarity', fontsize=11)\nax3.set_ylabel('Frequency', fontsize=11)\nax3.set_title('Dataset 2 (2016): Parent Terms', fontsize=12)\nax3.legend()\nax3.spines['top'].set_visible(False)\nax3.spines['right'].set_visible(False)\n\n# Dataset 2 - 2024\nax4 = axes[1, 1]\nvalues_d2_2024 = get_upper_triangle(jaccard_dataset2_2024)\nax4.hist(values_d2_2024, bins=50, edgecolor='black', alpha=0.7, color='purple')\nax4.axvline(x=values_d2_2024.mean(), color='red', linestyle='--', linewidth=2, \n            label=f'Mean = {values_d2_2024.mean():.3f}')\nax4.axvline(x=np.median(values_d2_2024), color='blue', linestyle='--', linewidth=2, \n            label=f'Median = {np.median(values_d2_2024):.3f}')\nax4.set_xlabel('Jaccard Similarity', fontsize=11)\nax4.set_ylabel('Frequency', fontsize=11)\nax4.set_title('Dataset 2 (2024): Parent Terms', fontsize=12)\nax4.legend()\nax4.spines['top'].set_visible(False)\nax4.spines['right'].set_visible(False)\n\nplt.tight_layout()\n\n# Save figure\noutput_images = repo_root / 'output/images'\nplt.savefig(output_images / \"jaccard_similarity_distributions_both_datasets.pdf\", \n            format=\"pdf\", dpi=300, bbox_inches='tight')\nplt.savefig(output_images / \"jaccard_similarity_distributions_both_datasets.jpeg\", \n            format=\"jpeg\", dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"Distribution plots saved to {output_images}/jaccard_similarity_distributions_both_datasets.pdf\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7duvc7vloan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify highly similar GO term pairs (Jaccard > 0.5)\n",
    "\n",
    "def find_similar_pairs(jaccard_matrix, threshold=0.5, top_n=10):\n",
    "    \"\"\"\n",
    "    Find GO term pairs with high Jaccard similarity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    jaccard_matrix : pd.DataFrame\n",
    "        Jaccard similarity matrix\n",
    "    threshold : float\n",
    "        Minimum Jaccard similarity to report\n",
    "    top_n : int\n",
    "        Number of top pairs to return\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Top similar GO term pairs with their similarity scores\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    n = len(jaccard_matrix)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            similarity = jaccard_matrix.iloc[i, j]\n",
    "            if similarity >= threshold:\n",
    "                pairs.append({\n",
    "                    'GO_term_1': jaccard_matrix.index[i],\n",
    "                    'GO_term_2': jaccard_matrix.columns[j],\n",
    "                    'jaccard_similarity': similarity\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(pairs)\n",
    "    if len(df) > 0:\n",
    "        df = df.sort_values('jaccard_similarity', ascending=False).head(top_n)\n",
    "    return df\n",
    "\n",
    "print(\"Highly Similar GO Term Pairs (Jaccard Similarity > 0.5)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nDataset 1 - 2016:\")\n",
    "similar_d1_2016 = find_similar_pairs(jaccard_dataset1_2016, threshold=0.5, top_n=10)\n",
    "if len(similar_d1_2016) > 0:\n",
    "    print(f\"Found {len(similar_d1_2016)} pairs with similarity > 0.5\")\n",
    "    display(similar_d1_2016)\n",
    "else:\n",
    "    print(\"No pairs with similarity > 0.5\")\n",
    "\n",
    "print(\"\\nDataset 1 - 2024:\")\n",
    "similar_d1_2024 = find_similar_pairs(jaccard_dataset1_2024, threshold=0.5, top_n=10)\n",
    "if len(similar_d1_2024) > 0:\n",
    "    print(f\"Found {len(similar_d1_2024)} pairs with similarity > 0.5\")\n",
    "    display(similar_d1_2024)\n",
    "else:\n",
    "    print(\"No pairs with similarity > 0.5\")\n",
    "\n",
    "print(\"\\nDataset 2 - 2016:\")\n",
    "similar_d2_2016 = find_similar_pairs(jaccard_dataset2_2016, threshold=0.5, top_n=10)\n",
    "if len(similar_d2_2016) > 0:\n",
    "    print(f\"Found {len(similar_d2_2016)} pairs with similarity > 0.5\")\n",
    "    display(similar_d2_2016)\n",
    "else:\n",
    "    print(\"No pairs with similarity > 0.5\")\n",
    "\n",
    "print(\"\\nDataset 2 - 2024:\")\n",
    "similar_d2_2024 = find_similar_pairs(jaccard_dataset2_2024, threshold=0.5, top_n=10)\n",
    "if len(similar_d2_2024) > 0:\n",
    "    print(f\"Found {len(similar_d2_2024)} pairs with similarity > 0.5\")\n",
    "    display(similar_d2_2024)\n",
    "else:\n",
    "    print(\"No pairs with similarity > 0.5\")\n",
    "\n",
    "# Count pairs at different thresholds\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Summary: Number of GO term pairs exceeding similarity thresholds\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "summary_data = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    summary_data.append({\n",
    "        'Threshold': threshold,\n",
    "        'Dataset1_2016': len(find_similar_pairs(jaccard_dataset1_2016, threshold=threshold, top_n=1000)),\n",
    "        'Dataset1_2024': len(find_similar_pairs(jaccard_dataset1_2024, threshold=threshold, top_n=1000)),\n",
    "        'Dataset2_2016': len(find_similar_pairs(jaccard_dataset2_2016, threshold=threshold, top_n=1000)),\n",
    "        'Dataset2_2024': len(find_similar_pairs(jaccard_dataset2_2024, threshold=threshold, top_n=1000))\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4k742timgv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze GO term pairs with LOW similarity (independent terms)\n",
    "\n",
    "def count_pairs_below_threshold(jaccard_matrix, thresholds):\n",
    "    \"\"\"\n",
    "    Count GO term pairs below various similarity thresholds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    jaccard_matrix : pd.DataFrame\n",
    "        Jaccard similarity matrix\n",
    "    thresholds : list\n",
    "        List of similarity thresholds to check\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping threshold to count of pairs below that threshold\n",
    "    \"\"\"\n",
    "    # Get upper triangle (exclude diagonal)\n",
    "    n = len(jaccard_matrix)\n",
    "    values = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            values.append(jaccard_matrix.iloc[i, j])\n",
    "    \n",
    "    values = np.array(values)\n",
    "    total_pairs = len(values)\n",
    "    \n",
    "    results = {}\n",
    "    for threshold in thresholds:\n",
    "        count = np.sum(values < threshold)\n",
    "        percentage = (count / total_pairs) * 100\n",
    "        results[threshold] = {'count': count, 'percentage': percentage}\n",
    "    \n",
    "    return results, total_pairs\n",
    "\n",
    "# Define thresholds to check\n",
    "thresholds = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "print(\"GO Term Pairs with LOW Similarity (Diversity Analysis)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nCounts show number of GO term pairs with similarity BELOW each threshold\")\n",
    "print(\"(Higher counts indicate more independent/diverse GO terms)\\n\")\n",
    "\n",
    "# Dataset 1 - 2016\n",
    "results_d1_2016, total_d1_2016 = count_pairs_below_threshold(jaccard_dataset1_2016, thresholds)\n",
    "print(f\"Dataset 1 - 2016 (Total pairs: {total_d1_2016})\")\n",
    "print(\"-\" * 60)\n",
    "for threshold in thresholds:\n",
    "    count = results_d1_2016[threshold]['count']\n",
    "    pct = results_d1_2016[threshold]['percentage']\n",
    "    print(f\"  Similarity < {threshold:.1f}: {count:6d} pairs ({pct:5.1f}%)\")\n",
    "\n",
    "# Dataset 1 - 2024\n",
    "results_d1_2024, total_d1_2024 = count_pairs_below_threshold(jaccard_dataset1_2024, thresholds)\n",
    "print(f\"\\nDataset 1 - 2024 (Total pairs: {total_d1_2024})\")\n",
    "print(\"-\" * 60)\n",
    "for threshold in thresholds:\n",
    "    count = results_d1_2024[threshold]['count']\n",
    "    pct = results_d1_2024[threshold]['percentage']\n",
    "    print(f\"  Similarity < {threshold:.1f}: {count:6d} pairs ({pct:5.1f}%)\")\n",
    "\n",
    "# Dataset 2 - 2016\n",
    "results_d2_2016, total_d2_2016 = count_pairs_below_threshold(jaccard_dataset2_2016, thresholds)\n",
    "print(f\"\\nDataset 2 - 2016 (Total pairs: {total_d2_2016})\")\n",
    "print(\"-\" * 60)\n",
    "for threshold in thresholds:\n",
    "    count = results_d2_2016[threshold]['count']\n",
    "    pct = results_d2_2016[threshold]['percentage']\n",
    "    print(f\"  Similarity < {threshold:.1f}: {count:6d} pairs ({pct:5.1f}%)\")\n",
    "\n",
    "# Dataset 2 - 2024\n",
    "results_d2_2024, total_d2_2024 = count_pairs_below_threshold(jaccard_dataset2_2024, thresholds)\n",
    "print(f\"\\nDataset 2 - 2024 (Total pairs: {total_d2_2024})\")\n",
    "print(\"-\" * 60)\n",
    "for threshold in thresholds:\n",
    "    count = results_d2_2024[threshold]['count']\n",
    "    pct = results_d2_2024[threshold]['percentage']\n",
    "    print(f\"  Similarity < {threshold:.1f}: {count:6d} pairs ({pct:5.1f}%)\")\n",
    "\n",
    "# Create summary dataframe\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Summary Table: Percentage of GO term pairs below each similarity threshold\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_data = []\n",
    "for threshold in thresholds:\n",
    "    summary_data.append({\n",
    "        'Threshold': f'< {threshold:.1f}',\n",
    "        'Dataset1_2016': f\"{results_d1_2016[threshold]['percentage']:.1f}%\",\n",
    "        'Dataset1_2024': f\"{results_d1_2024[threshold]['percentage']:.1f}%\",\n",
    "        'Dataset2_2016': f\"{results_d2_2016[threshold]['percentage']:.1f}%\",\n",
    "        'Dataset2_2024': f\"{results_d2_2024[threshold]['percentage']:.1f}%\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Overlapping GO Terms\n",
    "\n",
    "Remove redundant GO terms with Jaccard similarity > 0.1.\n",
    "\n",
    "Approach:\n",
    "- Use graph-based clustering to identify connected components of highly overlapping terms\n",
    "- For each cluster, select the GO term with greatest absolute percent change in gene count (2016â†’2024)\n",
    "- Filter based on 2016 Jaccard matrices (baseline year)\n",
    "- This ensures GO terms used in downstream analysis are reasonably independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_overlapping_go_terms(jaccard_matrix, dataset, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Remove redundant GO terms with Jaccard similarity > threshold.\n",
    "    \n",
    "    Uses greedy pairwise filtering: for each pair above threshold,\n",
    "    removes the GO term with lower absolute percent change.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    jaccard_matrix : pd.DataFrame\n",
    "        Symmetric matrix of Jaccard similarities (GO terms x GO terms)\n",
    "    dataset : pd.DataFrame\n",
    "        Dataset with columns: go_id, no_of_genes_in_hetio_GO_2016, \n",
    "        no_of_genes_in_GO_2024\n",
    "    threshold : float\n",
    "        Jaccard similarity threshold for redundancy (default 0.1)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    filtered_dataset : pd.DataFrame\n",
    "        Dataset containing only non-redundant GO terms\n",
    "    removed_terms : dict\n",
    "        Mapping {removed_go_id: kept_go_id}\n",
    "    removal_df : pd.DataFrame\n",
    "        Detailed information about removed pairs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate percent change for all GO terms\n",
    "    dataset_with_pct = dataset.copy()\n",
    "    dataset_with_pct['pct_change'] = abs(\n",
    "        (dataset_with_pct['no_of_genes_in_GO_2024'] - \n",
    "         dataset_with_pct['no_of_genes_in_hetio_GO_2016']) / \n",
    "        dataset_with_pct['no_of_genes_in_hetio_GO_2016'] * 100\n",
    "    )\n",
    "    \n",
    "    # Create lookup for percent change\n",
    "    pct_change_lookup = dict(zip(dataset_with_pct['go_id'], \n",
    "                                  dataset_with_pct['pct_change']))\n",
    "    \n",
    "    # Find all GO term pairs with similarity > threshold\n",
    "    pairs_to_filter = []\n",
    "    n = len(jaccard_matrix)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            similarity = jaccard_matrix.iloc[i, j]\n",
    "            if similarity > threshold:\n",
    "                go_id_i = jaccard_matrix.index[i]\n",
    "                go_id_j = jaccard_matrix.columns[j]\n",
    "                \n",
    "                pct_i = pct_change_lookup.get(go_id_i, 0)\n",
    "                pct_j = pct_change_lookup.get(go_id_j, 0)\n",
    "                \n",
    "                # Keep the one with higher percent change\n",
    "                if pct_i >= pct_j:\n",
    "                    keep_id = go_id_i\n",
    "                    remove_id = go_id_j\n",
    "                    keep_pct = pct_i\n",
    "                    remove_pct = pct_j\n",
    "                else:\n",
    "                    keep_id = go_id_j\n",
    "                    remove_id = go_id_i\n",
    "                    keep_pct = pct_j\n",
    "                    remove_pct = pct_i\n",
    "                \n",
    "                pairs_to_filter.append({\n",
    "                    'keep_id': keep_id,\n",
    "                    'remove_id': remove_id,\n",
    "                    'jaccard_similarity': similarity,\n",
    "                    'keep_pct': keep_pct,\n",
    "                    'remove_pct': remove_pct\n",
    "                })\n",
    "    \n",
    "    # Greedy removal: process pairs and track what's been removed\n",
    "    terms_to_remove = set()\n",
    "    removed_terms = {}\n",
    "    removal_details = []\n",
    "    \n",
    "    for pair in pairs_to_filter:\n",
    "        keep_id = pair['keep_id']\n",
    "        remove_id = pair['remove_id']\n",
    "        \n",
    "        # Skip if either term already removed\n",
    "        if keep_id in terms_to_remove or remove_id in terms_to_remove:\n",
    "            continue\n",
    "        \n",
    "        # Remove the lower percent change term\n",
    "        terms_to_remove.add(remove_id)\n",
    "        removed_terms[remove_id] = keep_id\n",
    "        \n",
    "        # Get full details for removal record\n",
    "        keep_row = dataset_with_pct[dataset_with_pct['go_id'] == keep_id].iloc[0]\n",
    "        remove_row = dataset_with_pct[dataset_with_pct['go_id'] == remove_id].iloc[0]\n",
    "        \n",
    "        removal_details.append({\n",
    "            'removed_go_id': remove_id,\n",
    "            'kept_go_id': keep_id,\n",
    "            'jaccard_similarity': pair['jaccard_similarity'],\n",
    "            'removed_genes_2016': remove_row['no_of_genes_in_hetio_GO_2016'],\n",
    "            'removed_genes_2024': remove_row['no_of_genes_in_GO_2024'],\n",
    "            'removed_pct_change': remove_row['pct_change'],\n",
    "            'kept_genes_2016': keep_row['no_of_genes_in_hetio_GO_2016'],\n",
    "            'kept_genes_2024': keep_row['no_of_genes_in_GO_2024'],\n",
    "            'kept_pct_change': keep_row['pct_change']\n",
    "        })\n",
    "    \n",
    "    # Filter dataset\n",
    "    filtered_dataset = dataset[~dataset['go_id'].isin(terms_to_remove)].copy()\n",
    "    \n",
    "    # Create removal dataframe\n",
    "    removal_df = pd.DataFrame(removal_details) if removal_details else pd.DataFrame()\n",
    "    \n",
    "    return filtered_dataset, removed_terms, removal_df\n",
    "\n",
    "print('Greedy pairwise filtering function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Dataset 1 based on 2016 Jaccard matrix\n",
    "print('Filtering Dataset 1 (all growth terms)...')\n",
    "print('=' * 80)\n",
    "\n",
    "dataset1_filtered, removed_d1, removal_details_d1 = filter_overlapping_go_terms(\n",
    "    jaccard_dataset1_2016, \n",
    "    dataset1_all_growth,\n",
    "    threshold=0.1\n",
    ")\n",
    "\n",
    "# Statistics\n",
    "print(f'\\nDataset 1 Statistics:')\n",
    "print(f'  GO terms before filtering: {len(dataset1_all_growth)}')\n",
    "print(f'  GO terms after filtering:  {len(dataset1_filtered)}')\n",
    "print(f'  GO terms removed:          {len(removed_d1)}')\n",
    "print(f'  Reduction:                 {len(removed_d1)/len(dataset1_all_growth)*100:.1f}%')\n",
    "\n",
    "# Show removed terms (if any)\n",
    "if len(removal_details_d1) > 0:\n",
    "    print(f'\\nRemoved Terms Details (Dataset 1, first 10):')\n",
    "    print(removal_details_d1[['removed_go_id', 'kept_go_id', 'jaccard_similarity', \n",
    "                               'removed_pct_change', 'kept_pct_change']].head(10).to_string(index=False))\n",
    "    print(f'\\n... and {len(removal_details_d1) - 10} more pairs removed') if len(removal_details_d1) > 10 else None\n",
    "else:\n",
    "    print(f'\\nNo overlapping GO terms found (all Jaccard < 0.1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Dataset 2 based on 2016 Jaccard matrix\n",
    "print('Filtering Dataset 2 (parent terms)...')\n",
    "print('=' * 80)\n",
    "\n",
    "dataset2_filtered, removed_d2, clusters_d2, removal_details_d2 = filter_overlapping_go_terms(\n",
    "    jaccard_dataset2_2016,\n",
    "    dataset2_parents,\n",
    "    threshold=0.1\n",
    ")\n",
    "\n",
    "# Statistics\n",
    "print(f'\\nDataset 2 Statistics:')\n",
    "print(f'  GO terms before filtering: {len(dataset2_parents)}')\n",
    "print(f'  GO terms after filtering:  {len(dataset2_filtered)}')\n",
    "print(f'  GO terms removed:          {len(removed_d2)}')\n",
    "print(f'  Reduction:                 {len(removed_d2)/len(dataset2_parents)*100:.1f}%')\n",
    "\n",
    "# Cluster distribution\n",
    "print(f'\\nCluster Distribution (Dataset 2):')\n",
    "print(clusters_d2.to_string(index=False))\n",
    "\n",
    "# Show removed terms (if any)\n",
    "if len(removal_details_d2) > 0:\n",
    "    print(f'\\nRemoved Terms Details (Dataset 2):')\n",
    "    print(removal_details_d2[['removed_go_id', 'representative_go_id', 'jaccard_similarity',\n",
    "                               'removed_pct_change', 'kept_pct_change']].to_string(index=False))\n",
    "else:\n",
    "    print(f'\\nNo overlapping GO terms found (all Jaccard < 01)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined summary table\n",
    "print('\\nCombined Summary: Before and After Filtering')\n",
    "print('=' * 80)\n",
    "\n",
    "# Calculate unique genes\n",
    "genes_d1_before = len(hetio_BPpG_dataset1[hetio_BPpG_dataset1['go_id'].isin(dataset1_all_growth['go_id'])]['neo4j_target_id'].unique())\n",
    "genes_d1_after = len(hetio_BPpG_dataset1[hetio_BPpG_dataset1['go_id'].isin(dataset1_filtered['go_id'])]['neo4j_target_id'].unique())\n",
    "\n",
    "genes_d2_before = len(hetio_BPpG_dataset2[hetio_BPpG_dataset2['go_id'].isin(dataset2_parents['go_id'])]['neo4j_target_id'].unique())\n",
    "genes_d2_after = len(hetio_BPpG_dataset2[hetio_BPpG_dataset2['go_id'].isin(dataset2_filtered['go_id'])]['neo4j_target_id'].unique())\n",
    "\n",
    "# GO-gene pairs\n",
    "pairs_d1_before = len(hetio_BPpG_dataset1[hetio_BPpG_dataset1['go_id'].isin(dataset1_all_growth['go_id'])])\n",
    "pairs_d1_after = len(hetio_BPpG_dataset1[hetio_BPpG_dataset1['go_id'].isin(dataset1_filtered['go_id'])])\n",
    "\n",
    "pairs_d2_before = len(hetio_BPpG_dataset2[hetio_BPpG_dataset2['go_id'].isin(dataset2_parents['go_id'])])\n",
    "pairs_d2_after = len(hetio_BPpG_dataset2[hetio_BPpG_dataset2['go_id'].isin(dataset2_filtered['go_id'])])\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': ['GO terms', 'Unique genes', 'GO-gene pairs', 'Terms removed', 'Clusters (size >= 2)'],\n",
    "    'Dataset 1 Before': [\n",
    "        len(dataset1_all_growth),\n",
    "        genes_d1_before,\n",
    "        pairs_d1_before,\n",
    "        '-',\n",
    "        '-'\n",
    "    ],\n",
    "    'Dataset 1 After': [\n",
    "        len(dataset1_filtered),\n",
    "        genes_d1_after,\n",
    "        pairs_d1_after,\n",
    "        len(removed_d1),\n",
    "        len(clusters_d1[clusters_d1['cluster_size'] >= 2])\n",
    "    ],\n",
    "    'Dataset 2 Before': [\n",
    "        len(dataset2_parents),\n",
    "        genes_d2_before,\n",
    "        pairs_d2_before,\n",
    "        '-',\n",
    "        '-'\n",
    "    ],\n",
    "    'Dataset 2 After': [\n",
    "        len(dataset2_filtered),\n",
    "        genes_d2_after,\n",
    "        pairs_d2_after,\n",
    "        len(removed_d2),\n",
    "        len(clusters_d2[clusters_d2['cluster_size'] >= 2])\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f'\\nFiltering complete. Use dataset1_filtered and dataset2_filtered for downstream analyses.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update GO-gene pair dataframes with filtered GO terms\n",
    "print('Updating GO-gene pair dataframes...')\n",
    "print('=' * 80)\n",
    "\n",
    "# Filter Dataset 1 BPpG\n",
    "hetio_BPpG_dataset1_filtered = hetio_BPpG_dataset1[\n",
    "    hetio_BPpG_dataset1['go_id'].isin(dataset1_filtered['go_id'])\n",
    "].copy()\n",
    "\n",
    "print(f'Dataset 1 GO-gene pairs:')\n",
    "print(f'  Before filtering: {len(hetio_BPpG_dataset1):,}')\n",
    "print(f'  After filtering:  {len(hetio_BPpG_dataset1_filtered):,}')\n",
    "print(f'  Removed:          {len(hetio_BPpG_dataset1) - len(hetio_BPpG_dataset1_filtered):,}')\n",
    "\n",
    "# Filter Dataset 2 BPpG\n",
    "hetio_BPpG_dataset2_filtered = hetio_BPpG_dataset2[\n",
    "    hetio_BPpG_dataset2['go_id'].isin(dataset2_filtered['go_id'])\n",
    "].copy()\n",
    "\n",
    "print(f'\\nDataset 2 GO-gene pairs:')\n",
    "print(f'  Before filtering: {len(hetio_BPpG_dataset2):,}')\n",
    "print(f'  After filtering:  {len(hetio_BPpG_dataset2_filtered):,}')\n",
    "print(f'  Removed:          {len(hetio_BPpG_dataset2) - len(hetio_BPpG_dataset2_filtered):,}')\n",
    "\n",
    "print(f'\\nFiltered dataframes created:')\n",
    "print(f'  - hetio_BPpG_dataset1_filtered')\n",
    "print(f'  - hetio_BPpG_dataset2_filtered')\n",
    "print(f'\\nUse these for downstream DWPC calculations to ensure GO term independence.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Filtered Datasets\n",
    "\n",
    "Compare gene counts (2016 vs 2024) for filtered GO term sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize filtered datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort filtered datasets\n",
    "dataset1_filt_sorted = dataset1_filtered.sort_values(\n",
    "    by='no_of_genes_in_hetio_GO_2016', \n",
    "    ascending=True\n",
    ").reset_index(drop=True)\n",
    "\n",
    "dataset2_filt_sorted = dataset2_filtered.sort_values(\n",
    "    by='no_of_genes_in_hetio_GO_2016',\n",
    "    ascending=True\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=150)\n",
    "\n",
    "# Dataset 1\n",
    "axes[0].scatter(\n",
    "    dataset1_filt_sorted.index,\n",
    "    dataset1_filt_sorted['no_of_genes_in_hetio_GO_2016'],\n",
    "    alpha=0.6,\n",
    "    label='2016',\n",
    "    s=20\n",
    ")\n",
    "axes[0].scatter(\n",
    "    dataset1_filt_sorted.index,\n",
    "    dataset1_filt_sorted['no_of_genes_in_GO_2024'],\n",
    "    alpha=0.6,\n",
    "    label='2024',\n",
    "    s=20\n",
    ")\n",
    "axes[0].set_xlabel('GO Term Index (sorted by 2016 gene count)')\n",
    "axes[0].set_ylabel('Number of Genes')\n",
    "axes[0].set_title(f'Dataset 1: All Growth Terms (Filtered)\\\\nn={len(dataset1_filtered)} GO terms')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dataset 2\n",
    "axes[1].scatter(\n",
    "    dataset2_filt_sorted.index,\n",
    "    dataset2_filt_sorted['no_of_genes_in_hetio_GO_2016'],\n",
    "    alpha=0.6,\n",
    "    label='2016',\n",
    "    s=20\n",
    ")\n",
    "axes[1].scatter(\n",
    "    dataset2_filt_sorted.index,\n",
    "    dataset2_filt_sorted['no_of_genes_in_GO_2024'],\n",
    "    alpha=0.6,\n",
    "    label='2024',\n",
    "    s=20\n",
    ")\n",
    "axes[1].set_xlabel('GO Term Index (sorted by 2016 gene count)')\n",
    "axes[1].set_ylabel('Number of Genes')\n",
    "axes[1].set_title(f'Dataset 2: Parent Terms (Filtered)\\\\nn={len(dataset2_filtered)} GO terms')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Visualization complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pvphters3ee",
   "metadata": {},
   "outputs": [],
   "source": "# Note: Jaccard similarity matrices are automatically cached during calculation\n# Cache location: output/jaccard_similarity/\n# Files:\n#   - jaccard_similarity_dataset1_2016.csv\n#   - jaccard_similarity_dataset1_2024.csv\n#   - jaccard_similarity_dataset2_2016.csv\n#   - jaccard_similarity_dataset2_2024.csv\n#\n# To force recalculation, delete the cache files and re-run the calculation cell\n\nprint(\"Jaccard similarity matrices are cached at:\")\nprint(f\"  {jaccard_cache_dir}/\")\nprint(\"\\nCached files:\")\nfor dataset in ['dataset1_2016', 'dataset1_2024', 'dataset2_2016', 'dataset2_2024']:\n    cache_file = jaccard_cache_dir / f\"jaccard_similarity_{dataset}.csv\"\n    if cache_file.exists():\n        file_size = cache_file.stat().st_size / 1024\n        print(f\"  jaccard_similarity_{dataset}.csv ({file_size:.1f} KB)\")\n    else:\n        print(f\"  jaccard_similarity_{dataset}.csv (not found)\")"
  },
  {
   "cell_type": "markdown",
   "id": "5wtpw3eji1p",
   "metadata": {},
   "source": [
    "### Summary: Jaccard Similarity Analysis\n",
    "\n",
    "This analysis computed pairwise Jaccard similarity between GO terms based on gene overlap for both datasets and years. Key insights:\n",
    "\n",
    "**Jaccard Similarity Formula:**\n",
    "- J(A,B) = |A âˆ© B| / |A âˆª B|\n",
    "- Ranges from 0 (no overlap) to 1 (complete overlap)\n",
    "\n",
    "**Implementation:**\n",
    "- Uses sklearn.metrics.pairwise_distances for optimized computation (10-50x faster than nested loops)\n",
    "- Results are automatically cached to disk for instant loading on subsequent runs\n",
    "- Cache location: output/jaccard_similarity/\n",
    "\n",
    "**Analysis Components:**\n",
    "1. Computed similarity matrices for all GO term pairs in both datasets\n",
    "2. Generated clustered heatmaps showing pairwise similarity patterns with hierarchical clustering\n",
    "3. Diagonal removed from heatmaps to focus on GO term relationships\n",
    "4. Analyzed distribution of similarity scores\n",
    "5. Identified highly similar GO term pairs that may represent functional redundancy or hierarchical relationships\n",
    "\n",
    "**Outputs:**\n",
    "- Similarity matrices cached in output/jaccard_similarity/\n",
    "- Clustered heatmaps and distributions saved to output/images/\n",
    "\n",
    "**Applications:**\n",
    "- Identify redundant or highly overlapping GO terms\n",
    "- Understand functional relationships between biological processes\n",
    "- Inform feature selection for machine learning (remove highly correlated features)\n",
    "- Validate that filtered datasets have appropriate diversity\n",
    "- Clustering reveals functional modules and related biological processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ti4nty21jgk",
   "metadata": {},
   "source": [
    "### Gene Overlap Analysis: Jaccard Similarity Between GO Terms\n",
    "\n",
    "Calculate pairwise Jaccard similarity between GO terms based on their annotated genes. This measures how much gene sets overlap between different GO terms, which can reveal functional relationships and redundancy in the ontology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ixxuz7sh7ma",
   "metadata": {},
   "source": [
    "### Visualize Gene Count Changes: 2016 vs 2024\n",
    "\n",
    "This visualization compares the number of genes associated with each GO term between 2016 and 2024 for both filtered datasets. GO terms are sorted by their 2016 gene count for easier comparison of growth patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save filtered datasets - 2016 data\nprint('Saving filtered datasets (2016)...')\n\noutput_intermediate = repo_root / 'output/intermediate'\n\ndataset1_filtered.to_csv(\n    output_intermediate / 'dataset1_filtered.csv',\n    index=False\n)\nprint(f'Saved dataset1_filtered.csv: '\n      f'{len(dataset1_filtered)} GO terms')\n\ndataset2_filtered.to_csv(\n    output_intermediate / 'dataset2_filtered.csv',\n    index=False\n)\nprint(f'Saved dataset2_filtered.csv: '\n      f'{len(dataset2_filtered)} GO terms')\n\nhetio_BPpG_dataset1_filtered.to_csv(\n    output_intermediate / 'hetio_bppg_dataset1_filtered.csv',\n    index=False\n)\nprint(f'Saved hetio_bppg_dataset1_filtered.csv: '\n      f'{len(hetio_BPpG_dataset1_filtered)} rows')\n\nhetio_BPpG_dataset2_filtered.to_csv(\n    output_intermediate / 'hetio_bppg_dataset2_filtered.csv',\n    index=False\n)\nprint(f'Saved hetio_bppg_dataset2_filtered.csv: '\n      f'{len(hetio_BPpG_dataset2_filtered)} rows')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i5tn9j0ffo",
   "metadata": {},
   "outputs": [],
   "source": "# Filter and save 2024 datasets with filtered GO terms\nprint('\\nFiltering and saving 2024 datasets...')\nprint('=' * 80)\n\n# Filter 2024 Dataset 1 to only filtered GO terms\nupd_go_bp_2024_dataset1_filtered = upd_go_bp_2024_dataset1[\n    upd_go_bp_2024_dataset1['go_id'].isin(dataset1_filtered['go_id'])\n].copy()\n\nprint(f'Dataset 1 (2024):')\nprint(f'  Before filtering: {len(upd_go_bp_2024_dataset1):,} GO-gene pairs')\nprint(f'  After filtering:  {len(upd_go_bp_2024_dataset1_filtered):,} GO-gene pairs')\nprint(f'  Unique GO terms:  {upd_go_bp_2024_dataset1_filtered[\"go_id\"].nunique()}')\nprint(f'  Unique genes:     {upd_go_bp_2024_dataset1_filtered[\"neo4j_target_id\"].nunique()}')\n\n# Filter 2024 Dataset 2 to only filtered GO terms\nupd_go_bp_2024_dataset2_filtered = upd_go_bp_2024_dataset2[\n    upd_go_bp_2024_dataset2['go_id'].isin(dataset2_filtered['go_id'])\n].copy()\n\nprint(f'\\nDataset 2 (2024):')\nprint(f'  Before filtering: {len(upd_go_bp_2024_dataset2):,} GO-gene pairs')\nprint(f'  After filtering:  {len(upd_go_bp_2024_dataset2_filtered):,} GO-gene pairs')\nprint(f'  Unique GO terms:  {upd_go_bp_2024_dataset2_filtered[\"go_id\"].nunique()}')\nprint(f'  Unique genes:     {upd_go_bp_2024_dataset2_filtered[\"neo4j_target_id\"].nunique()}')\n\n# Save 2024 filtered datasets\noutput_intermediate = repo_root / 'output/intermediate'\nupd_go_bp_2024_dataset1_filtered.to_csv(\n    output_intermediate / 'hetio_bppg_dataset1_2024_filtered.csv',\n    index=False\n)\nprint(f'\\nSaved hetio_bppg_dataset1_2024_filtered.csv: {len(upd_go_bp_2024_dataset1_filtered):,} rows')\n\nupd_go_bp_2024_dataset2_filtered.to_csv(\n    output_intermediate / 'hetio_bppg_dataset2_2024_filtered.csv',\n    index=False\n)\nprint(f'Saved hetio_bppg_dataset2_2024_filtered.csv: {len(upd_go_bp_2024_dataset2_filtered):,} rows')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0w7lk8p9n4t",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 80)\n",
    "print('NOTEBOOK 1.3 COMPLETE - ALL DATASETS SAVED')\n",
    "print('=' * 80)\n",
    "\n",
    "print('\\nOutput Summary:')\n",
    "print('  GO Term Lists (year-agnostic):')\n",
    "print(f'    - dataset1_filtered.csv ({len(dataset1_filtered)} GO terms)')\n",
    "print(f'    - dataset2_filtered.csv ({len(dataset2_filtered)} GO terms)')\n",
    "\n",
    "print('\\n  2016 BP-Gene Associations with Neo4j IDs:')\n",
    "print(f'    - hetio_bppg_dataset1_filtered.csv ({len(hetio_BPpG_dataset1_filtered):,} pairs)')\n",
    "print(f'    - hetio_bppg_dataset2_filtered.csv ({len(hetio_BPpG_dataset2_filtered):,} pairs)')\n",
    "\n",
    "print('\\n  2024 BP-Gene Associations with Neo4j IDs:')\n",
    "print(f'    - hetio_bppg_dataset1_2024_filtered.csv ({len(upd_go_bp_2024_dataset1_filtered):,} pairs)')\n",
    "print(f'    - hetio_bppg_dataset2_2024_filtered.csv ({len(upd_go_bp_2024_dataset2_filtered):,} pairs)')\n",
    "\n",
    "print('\\nDataset Comparison:')\n",
    "print(f'  Dataset 1: {len(hetio_BPpG_dataset1_filtered):,} (2016) -> {len(upd_go_bp_2024_dataset1_filtered):,} (2024) pairs')\n",
    "print(f'  Dataset 2: {len(hetio_BPpG_dataset2_filtered):,} (2016) -> {len(upd_go_bp_2024_dataset2_filtered):,} (2024) pairs')\n",
    "\n",
    "print('\\nNext: Run notebook 1.4 to generate permuted datasets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}